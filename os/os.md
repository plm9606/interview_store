# 운영체제

- [주소 바인딩](#주소-바인딩)
- [운영체제의 메모리 관리](#운영체제의-메모리-관리)
- [가상 메모리](#가상-메모리)
  - [요구 페이징 기법](#요구-페이징-기법)
  - [페이지 부재](#페이지-부재)
  - [페이지 교체](#페이지-교체)
  - [스레싱](#스레싱)

# 주소 바인딩

프로세스는 실행을 위해 메모리에 적재되면 프로세스를 위한 독자적인 주소공간이 생긴다. 이 주소를 `논리적 주소`라고 한다. 논리적 주소는 각 프로세스마다 `독립적`으로 할당된다.

> 왜 프로세스는 논리적 주소를 사용할까?

CPU가 프로세스의 작업을 수행하기 위해서 프로세스의 논리적 주소를 참조하게 된다. 논리적 주소만으로는 실제 메모리의 주소를 알 수 없기 때문에 **논리 주소를 물리적 메모리로 연결시키는 작업**이 필요하다. 이 작업을 `주소 바인딩`이라고 한다.

주소 바인딩에는

- 컴파일 타임 바인딩
- 로드 타임 바인딩
- 실행 시간 바인딩

이렇게 세가지 바인딩 방식이 있다. 세 바인딩의 기준은 **물리적 주소가 언제 결정되느냐**에 따라서 결정된다.

### 컴파일 타임 바인딩

말 그대로 컴파일 할 때 물리적 메모리 주소가 결정되는 주소 바인딩이다.
프로그램의 물리적 주소를 변경하고 싶으면 다시 컴파일해야 한다.

이 방식은 비현실적이고 현대의 시분할 컴퓨팅 환경에서는 잘 사용되지 않는 기법이다.

### 로드 타임 바인딩

프로그램의 실행이 시작될 때 물리적 주소가 결정된다.
이 바인딩에서는 `로더`가 물리적 메모리 주소를 부여하고 프로그램이 종료될 때 까지 물리주소가 고정된다.

로더: 사용자 프로그램을 메모리에 적재시키는 프로그램

### 실행 시간 바인딩(run time binding)

프로그램이 실행한 후에도 물리적 주소가 변경될 수 있는 바인딩 방식이다.
런타임 바인딩에서는 CPU가 주소를 참조할 때마다 해당 데이터가 물리적 메모리의 어느 위치에 존재하는지 `주소 매핑 테이블`을 이용해 주소 바인딩을 점검한다.
그리고 주소 매핑 테이블 뿐 만 아니라 `기준 레지스터`, `한계 레지스터`, `MMU(Memeoty Management Unit`이 필요하다.
런타임 바인딩은 메모리에 프로세스의 주소공간이 연속적으로 적재되어 있음을 가정한다.

- 기준 레지스터: 프로세스의 물리적 메모리의 시작 주소를 가지고 있다.
- 한계 레지스터: 현재 CPU에서 수행중인 프로세스의 논리적 주소의 최대값, 프로세스의 크기를 가지고 있다.
- MMU: 논리적 주소를 물리적 주소로 메핑해주는 하드웨어

![image.png](https://images.velog.io/post-images/adam2/53b752a0-327f-11ea-89c2-a9689e76c48b/image.png)

### MMU 동작 방식

기준 레지스터에는 현재 CPU에서 수행중인 프로세스의 물리적 메모리 시작 주소가 저장되어 있다. CPU가 논리적 주소 245에 있는 데이터를 요청하게 되면 **기준 레지스터에 저장된 물리적 시작 주소와 해당 논리적 주소를 더한다.** 그렇게해서 실제 메모리의 8245에 있는 데이터를 꺼내오면 된다.

**그렇다면 한번 생각해보자🤔**
프로세는 고유한 주소공간을 가지고 있다. 그리고 논리적 주소값은 프로세스마다 독립적으로 할당된다고 하였다. 프로세스A에도 100번 논리 주소가, 프로세스B에도 100번 논리주소가 있다는 말이다. 그렇지만 프로세스A의 100번 논리주소에 매핑되는 실제 물리적 주소와 프로세스B에 매핑되는 실제 물리적 주소는 다를 것이다.
따라서 MMU기법에서는 **문맥교환이 일어날 때 마다 기준 레지스터의 값을 바뀌는 프로세스에 해당되는 값으로 `재설정`을 해주어야 한다.**

### 한계 레지스터가 필요한 이유

MMU 방식에서는 `기준레지스터값 + 논리적 주소값`을 통해서 주소 바인딩을 한다.
만약 **해당 값이 해당 프로세스의 주소범위를 넘어가는 값이 된다면 어떻게 될까?** 프로세스가 접근해서는 안되는 영역을 접근할 가능성이 생긴다.
이런 문제점을 방지하기 위해서 한계레지스터를 사용하는 것이다.
한계 레지스터에 최대 논리적 주소값을 저장하고 CPU가 논리적 주소를 요청할 때 마다 한계 레지스터 값보다 작은 값인지를 검사하게 된다.

## ⚙여러가지 메모리 관리 기법

### 동적 로딩

프로세스가 실행될 때 프로세스 주소공간 전체를 메모리에 올리지 않고, 필요한 부분만 그때 그때 메모리에 적재하는 방식

- 메모리 효율적 사용 가능
- 프로스램 자체에서 구현 가능

### 동적 연결

linking: 소스코드를 컴파일하여 이미 컴파일된 라이브러리 파일들과 묶어(linking) 하나의 실행파일을 생성하는 것

동적 연결은 컴파일한 소스코드와 라이브러리파일을 바로 연결하지 않고 프로그램이 실행되고 라이브러리 함수를 호출할 때 라이브러리 파일과 linking하는 방식.

- 실행 파일에 라이브러리 코드가 포함되지 않는다.
- 공통으로 사용하는 라이브러리를 메모리에 한번만 적재해서 메모리 효율 ↑
- 운영체제의 지원 필요

### 스와핑

메모리에 올라온 프로세스의 주소공간 전체를 디스크의 swap 영역으로 이동시키는 것을 말한다.

swap 영역은 backing store라고도 부르고, 디스크 내에 파일 시스템과는 별도로 존재하는 영역이다.

스와핑을 하는 이유는 메모리에 너무 많은 프로세스가 적재되어서 시스템 성능이 떨어지게 되면 그중 당장 사용하지 않는 몇개의 프로세스를 스왑 영역으로 내쫒아 메모리공간을 확보하기 위해서이다.

이 작업은 중기 스케줄러가 담당하여 처리한다.

![image.png](https://images.velog.io/post-images/adam2/831fd460-3282-11ea-bcba-71396290533a/image.png)

## 동기화란?

공유 자원에 대하여 동시에 접근하는 프로세스/스레드들로 인해 발생하는 문제를 해결하기 위해 행하는 방식.

### 교착 상태(데드락)의 4가지 조건

1. 상호배제(Mutual exclusion) : 프로세스들이 필요로 하는 자원에 대해 배타적인 통제권을 요구한다.
2. 점유대기(Hold and wait) : 프로세스가 할당된 자원을 가진 상태에서 다른 자원을 기다린다.
3. 비선점(No preemption) : 프로세스가 어떤 자원의 사용을 끝날 때까지 그 자원을 뺏을 수 없다.
4. 순환대기(Circular wait): 각 프로세스는 순환적으로 다음 프로세스가 요구하는 자원을 가지고 있다.

이 조건 중 한 가지라도 만족하지 않으면 교착 상태는 발생하지 않는다. 순환대기 조건은 점유대기 조건과 비선점 조건을 만족해야 성립하는 조건이므로 위 4가지 조건은 서로 완전히 독립적이지 않다.

해결 방법

1. 교착 상태의 예방
2. 교착 상태의 회피
3. 교착 상태의 무시
4. 교착 상태의 발견

## 운영체제의 메모리 관리

운영체제는 자원의 효율적인 관리를 도맏아 하는 소프트웨어이다.
따라서 운영체제는 어떤 프로그램에 얼마만큼의 메모리를 할당해야 할지를 결정해야한다.

메모리 할당 방법에는

- 균등 할당
- 비례 할당
- 우선순위 할당

세가지 방법이 있다.
균등할당은 프로세스마다 동일한 메모리를 할당하는 방식이고, 비례할당은 프로세스의 크기에 비례하게 메모리를 할당하는 방식, 우선순위 할당은 우선순위가 높은 프로세스에게 더 많은 메모리를 할당하는 방식이다.

또한 운영체제는 프로세스를 통째로 메모리에 올릴 수 있지만 CPU에서 당장 수행해야 할 부분만 메모리에 올리고 나머지는 디스크의 swap 영역에 두어 메모리를 효율적으로 사용한다.

## 가상 메모리

운영체제는 프로그램이 자기 자신만의 가상 메모리를 사용하는 것처럼 가정해 프로그램 하는 것을 지원한다. 가상 메모리 주소 공간은 논리적 주소로서 모든 프로그램마다 0부터 시작하게 된다.
즉, 가상메모리는 프로세스마다 논리적 주소공간을 가지고 이 주소공간의 일부는 물리적 메모리에 적재되고 일부는 스왑영역에 존재한다.

### 장점

- 메모리 사용량 감소 (프로세스 일부만 올리니까)
- 입출력 오버헤드 감소 ( 일부만 디스크 -> 메모리 입출력 하니까)
- 시스템이 더 많은 프로세스를 수용할 수 있다.
- 프로그램이 물리적 메모리의 용량 제약에서 자유롭다 (메모리보다 큰 프로그램 실행 가능)

가상메모리 기법은 프로세스의 주소공간을 적재하는 단위에 따라 `요구 페이징 기법`과 `요구 세그멘테이션 기법` 두개로 나눌 수 있다.

## 요구 페이징 기법

페이지 단위로 프로세스의 주소공간을 메모리에 적재하며 당장 사용될 페이지만을 메모리에 적재한다.

### 페이지 부재

CPU에서 요청한 페이지가 현재 메모리에 없어 `유효-무효 비트`가 무효로 세팅되어 있는 경우를 말한다.
페이지 부재 발생 시 페이지를 디스크에서 읽어와야 하는데 이 과정에서 막대한 overhead가 발생한다. 따라서 요구 페이징 기법은 페이지 부재 발생률이 성능에 큰 영향을 끼친다.

**페이지 부재 시 동작 과정**

1. MMU(Memory Management Unit)가 페이지 부재 트랩을 발생시킨다. (트랩=소프트웨어 인터럽트)
2. 인터럽트로 인해 커널모드로 전환되어 OS의 페이지 부재 처리 루틴이 호출된다.
3. 해당 부재 페이지의 보호비트를 참조해 접근이 가능한지 체크한다.
4. 물리메모리에 비어있는 프레임을 할당받고 그곳에 페이지를 읽어온다.
5. 페이지를 읽어오는 동안 프로세스는 wait상태가 된다.
6. 디스크 입출력 완료시 인터럽트를 발생시키고 해당 페이지의 유효-무효 비트를 유효로 세팅한다

### 페이지 교체

페이지 부재 발생시 메모리에 해당 페이지를 적재해야 하는데 이때 메모리가 꽉찼다면 어떡해야 할까??
이때는 메모리에 있는 페이지중 가장 쓸모 없어보이는 것을 골라 스왑 영역으로 쫒아내고 그 자리에 페이지 부재된 페이지를 적재해야 한다. 이 과정이 페이지 교체이다.

교체할 페이지를 선정할 때 교체 대상이 될 프레임의 범위에 따라 `전역 교체`와 `지역 교체`로 나눌 수 있다.
전역교체 방법은 모든 페이지 프레임이 교체 대상이 될 수 있는 방법이다. 지역 교체 방법은 현재 수행중인 프로세스에게 할당된 페이지 프레임 내에서만 페이지 교환을 하는 방법이다.

**페이지 교체 알고리즘**

- 최적 교체(OPT) 알고리즘
- FIFO
- LRU(Least Recently Used)
- LFU(Least Frequently Used)
- NUR(Not Used Recently)

#### 최적 페이지 교체 알고리즘

각 페이지의 호출 순서를 미리 알고있는 전제 하에 알고리즘을 운영
가장 먼 미래에 호출될 페이지와 교체한다.
실제로 구현할수 없다.

#### LRU

가장 과거에 호출되었던 페이지와 교체한다.
`시간 지역성`을 활용

> 최근에 참조된 페이지가 다시 참조될 가능성이 높다

#### LFU

가장 적은 횟수로 참조된 페이지와 교체한다.
`Incache-LFU`, `Perfect-LFU`

#### NUR(클럭 알고리즘)

`LRU 근사 알고리즘`이다.
LRU처럼 오랫동안 참조하지 않은 페이지중 하나를 선택하지만 가장 오래된 페이지라는 보장은 없다.
`하드웨어적 지원`을 통해 알고리즘을 운영해 오버헤드를 줄임
페이지 프레임의 `참조 비트`를 조사해서 참조비트가 `0`인 페이지를 찾으면 그 페이지와 교체한다

### 스레싱

프로세스의 처리 시간보다 페이지 교체에 드는 시간이 더 많아져 CPU이용률이 떨어지는 현상을 말한다.
다중프로그래밍정도가 높아지면 어느정도 까지는 CPU이용률이 오르지만, 한계치를 넘으면 스레싱이 발생하고 CPU이용률이 급감한다.

> 다중프로그래밍정도: 메모리에 동시에 올라가 있는 프로세스의 수

**해결책**

- 다중프로그래밍정도를 적정 수준으로 유지한다.
- 페이지 부재 빈도를 조절한다
- working set을 유지한다
- 일부 프로세스를 중단한다
